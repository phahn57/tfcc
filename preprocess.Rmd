---
title: "preprocessing"
author: "Peter Hahn"
date: "11 11 2018"
output: html_document
---
## all stuff for running of juli_stm and app because loading of data and stm processing take to much time


```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = TRUE, message=FALSE, fig.width = 12, fig.height = 8)
## load libraries
library(tidyverse)
library(RISmed)
library(wordcloud)
library(stringr)
library(tm)
library(tidytext)
library(widyr)
library(topicmodels)
library(furrr)
library(lda)
library(reshape2)
library(ldatuning)
```

## routine for loading new query use saved * csv instead 
```{r}
        res1 <- EUtilsSummary("((Triangular Fibrocartilage[MeSH Terms]) OR TFCC)" , 
                      type = "esearch", 
                      db = "pubmed",
                      datetype = "pdat",
                      retmax = 12000,
                      mindate = 1950, 
                      maxdate = 2019)

        fetch <- EUtilsGet(res1, type = "efetch", db = "pubmed")

        abstracts <- data.frame(title = fetch@ArticleTitle,
                                abstract = fetch@AbstractText, 
                                journal = fetch@Title,
                                DOI = fetch@PMID, 
                                year = fetch@YearPubmed)
        ## ensure abstracts are character fields (not factors)
        abstracts <- abstracts %>% mutate(abstract = as.character(abstract)) %>% filter(abstract!="")
        # make bins for publication year
        #abstracts$year_cut <- cut(abstracts$year, c(1960, 1970, 1980, 1990, 2000,2010,2018),labels=c("60-69","70-79","80-89","90-99","00-09","10-18"), include.lowest=TRUE)

        ## remove plural words
       pm_data <-abstracts  %>% mutate(abstract=str_replace_all(abstract,"options","option")) 
# list of words to remove in token
        del_word <-  tibble(word=c("tfcc","tfc","TFCC","NA","patient","disease","treatment","study","result","hand","disease",
                                "patients","clinical","results","report","included","month","treated","found","increased","compared","95","ci","10","20","30","statistically","lt","studies","underwent","diagnosis","12","15","50","reported","de","quot","des","bev","major","dd","ii","iii","mm","cm","wrist"))
 
        ### build data frame with first authors
        MedList = mapply(cbind, "ID"=ArticleId(fetch),Author(fetch),SIMPLIFY = FALSE)
        first_author <-melt(MedList,id.vars=c("ID","LastName","order")) %>% filter(order==1) %>% filter(variable=="Initials") 
        first_author$L1 <- as.integer(first_author$L1)
        first_author <- first_author %>% select(LastName,value,L1)
        write.csv(first_author,"first_author.csv")
```

```{r}
         pm_abstract <- pm_data %>% 
                unnest_tokens(word,abstract) %>% 
                filter(!str_detect(word, "[0-9]+")) %>%
                anti_join(stop_words)  %>% anti_join(del_word)
```

### make sparse matrix and 

```{r}

        word_counts <- pm_abstract %>% 
        count(DOI,word,sort=TRUE) %>% ungroup() %>% droplevels()
```



## build document term matrix for further analysis two ways
```{r}
        abstr_dtm <- word_counts %>% 
        cast_dtm(DOI,word,n)

        # abstr_sparse <- word_counts %>% 
        #         cast_sparse(DOI,word,n)
```

### use lda_tuning
```{r}

                system.time({
  tunes <- FindTopicsNumber(
    dtm = abstr_dtm,
    topics = seq(from = 20, to = 100, by = 10),
    metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010"),
    method = "Gibbs",
    control = list(seed = 12345),
    mc.cores = 4L,
    verbose = TRUE
  )
})

```

```{r}
FindTopicsNumber_plot(tunes)
```



## final model with k = 48 , fits better in rows on screen :-)

```{r}
topic_model <- stm(abstr_sparse, K = 48, 
                   verbose = FALSE, init.type = "Spectral")


```
 
## alternative with LD
```{r}
        abstr_lda <- LDA(abstr_dtm,k=40,control=list(seed=1234))
```


